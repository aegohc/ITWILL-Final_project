'''
2021.07.26 기록
저희 팀은 4명으로 구성되었으며, 전부 비전공자였습니다. (이번 기회를 통해 코딩을 하게된 사람들)
첫째로 각자 팀원 소개 및 주제에 대한 가닥을 잡았습니다.
우선 왜 이주제를 선택하였는지, 이 주제로 하고싶었던건 무엇이었는지
팀원간 목적의식을 명확하게 하는데 집중하였습니다. 
1] sns나 언론 데이터는 편향적이고 왜곡될 가능성이 있어, 보다 실질적인 데이터인
민원 데이터를 분석하는 것으로 결정되었습니다.
2] 텍스트 분석과 이 분석을 통해 문제를 찾거나 해결하는 것을 궁극적으로 하고싶다는
것으로 의견이 통일되었습니다.
3] 공공데이터 포털에서 데이터를 사용하고자 한 시도는 데이터 수와 종류의 적음과(대부분 수치 데이터라, 프로젝트의 목적과 불일치)
xml파일의 오픈키가 제대로 작동되지 않는 문제 때문에 보류하기로 하였습니다.
4] 신문고 사이트의 데이터 및 민원 빅데이터 사이트를 확인 후, 신문고 사이트의 민원 데이터를 크롤링하는
것으로 가닥을 잡았습니다. 크롤링할 사이트는 신문고 사이트로 결정하였습니다.
1. 민원 빅데이터
https://bigdata.epeople.go.kr/bigdata/pot/stst/mwkwrd/forwardStstMwkwrd.npaid?dspMenuId=P0053&dspLinkMenuId=P0053&_csrf=5616981b-d82e-46d3-8c24-9b72eed849aa
2. 신문고 사이트(크롤링 대상)
https://www.epeople.go.kr/nep/pttn/gnrlPttn/pttnSmlrCaseList.npaid
5] 이후 1주차~4주차 사이의 간단한 개발 계획을 정하였고, 일정의 빡빡함을 대비하여 마지막 주를 여유주로 두고 3주간 개발 과정으로 결정하였습니다.
  1주차 = 데이터 수집 및 전처리
  2주차 = 데이터의 탐색적 분석 및 모델링
  3주차 = 모델링 분석 및 문제 발견, 해결 방안 제시 및 제출용 ppt 작성
  4주차(3일) = 여분 시간
6] 오후 시간대에는 각자 크롤링을 시도하는 것으로 종료하였습니다.



2021.07.27 기록
첫 대면 회의 시작
1] url을 통한 웹크롤링은 불가능함을 확인 -> selenium을 통한 웹 스크래핑을 하기로 결정
2] git-hub을 통해 코드 결과를 공유하기로 결정, 간단한 git-hub사용방법을 배움(by 오지애님)
3] git-hub 프로젝트 공유 완료, test file인 'Crawling_test.py' 생성.
4] 한명이 안모이는 것의 불편함을 확인, 미리미리 학원에 예약을 할 필요성을 느낌
5] 각자 크롤링 및 스크래핑 시도 시작.


'''
